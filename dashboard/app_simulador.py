# dashboard/app.py
from flask import Flask, jsonify, render_template, request, send_file
import psycopg2
from datetime import datetime, timedelta
import random
import threading
import time
import csv
import io
from collections import defaultdict
import sys
import os

# Agregar directorio bi al path
sys.path.append(os.path.join(os.path.dirname(__file__), '..'))

# Importar m√≥dulos BI
from bi.ml_models import InvernaderoMLModels, ClusteringModels
from bi.pca_analysis import PCAAnalyzer
from bi.etl_process import ETLProcessor
from bi.olap_queries import OLAPAnalyzer

app = Flask(__name__)

# Inicializar m√≥dulos BI (se inicializar√°n despu√©s de conectar a BD)
ml_models = None
pca_analyzer = None
etl_processor = None
olap_analyzer = None

# Variable global para controlar el simulador
simulador_activo = False
simulador_thread = None
ultima_prediccion = None

def get_db_connection():
    """Conectar a la base de datos greenhouse_monitoring"""
    try:
        conn = psycopg2.connect(
            host="localhost",
            database="invernadero_bio",
            user="edgar",
            password="12345",
            port="5432"
        )
        return conn
    except Exception as e:
        print(f"Error de conexi√≥n: {e}")
        return None

def inicializar_base_datos():
    """Inicializar la base de datos si no existe"""
    conn = get_db_connection()
    if not conn:
        print("‚ùå No se pudo conectar a la base de datos")
        return False
    
    cursor = conn.cursor()
    try:
        # Crear tablas si no existen
        cursor.execute("""
            CREATE TABLE IF NOT EXISTS plants (
                plant_id SERIAL PRIMARY KEY,
                plant_type VARCHAR(50),
                planting_date TIMESTAMP,
                status VARCHAR(20)
            )
        """)
        
        cursor.execute("""
            CREATE TABLE IF NOT EXISTS sensor_data (
                id SERIAL PRIMARY KEY,
                sensor_id VARCHAR(50),
                temperature DECIMAL(5,2),
                humidity DECIMAL(5,2),
                soil_moisture DECIMAL(5,2),
                nutrient_level DECIMAL(5,2),
                ph_level DECIMAL(4,2),
                light_intensity DECIMAL(8,2),
                co2_level DECIMAL(6,2),
                timestamp TIMESTAMP
            )
        """)
        
        cursor.execute("""
            CREATE TABLE IF NOT EXISTS predictions (
                prediction_id SERIAL PRIMARY KEY,
                plant_id INTEGER,
                predicted_yield DECIMAL(8,2),
                prediction_date TIMESTAMP,
                confidence DECIMAL(4,3)
            )
        """)
        
        # Insertar plantas de ejemplo si no existen
        cursor.execute("SELECT COUNT(*) FROM plants")
        if cursor.fetchone()[0] == 0:
            plantas = [
                ('rabano', 'active'),
                ('rabano', 'active'), 
                ('cilantro', 'active'),
                ('cilantro', 'active'),
                ('rabano', 'active'),
                ('cilantro', 'active')
            ]
            for tipo_planta, estado in plantas:
                cursor.execute(
                    "INSERT INTO plants (plant_type, planting_date, status) VALUES (%s, %s, %s)",
                    (tipo_planta, datetime.now() - timedelta(days=10), estado)
                )
            print("‚úÖ 6 plantas de ejemplo creadas (3 r√°banos, 3 cilantros)")
        
        conn.commit()
        print("‚úÖ Base de datos inicializada correctamente")
        return True
        
    except Exception as e:
        print(f"‚ùå Error inicializando base de datos: {e}")
        conn.rollback()
        return False
    finally:
        cursor.close()
        conn.close()

def generar_datos_sensor():
    """Generar datos realistas de sensores"""
    sensores = [
        {'id': 'sensor_rabano_1', 'type': 'rabano'},
        {'id': 'sensor_rabano_2', 'type': 'rabano'},
        {'id': 'sensor_cilantro_1', 'type': 'cilantro'},
        {'id': 'sensor_cilantro_2', 'type': 'cilantro'}
    ]
    
    conn = get_db_connection()
    if not conn:
        return
    
    cursor = conn.cursor()
    
    try:
        for sensor in sensores:
            if sensor['type'] == 'rabano':
                temp_base = 22.0
                hum_base = 65.0
            else:
                temp_base = 21.0
                hum_base = 70.0
            
            # Variaciones realistas
            hora = datetime.now().hour
            es_dia = 6 <= hora <= 18
            
            temp = temp_base + random.uniform(-2, 2)
            hum = hum_base + random.uniform(-8, 8)
            nutrientes = 1.7 + random.uniform(-0.3, 0.3)
            ph = 6.6 + random.uniform(-0.2, 0.2)
            luz = random.uniform(800, 1200) if es_dia else random.uniform(50, 200)
            
            datos = {
                'sensor_id': sensor['id'],
                'temperature': round(max(18, min(28, temp)), 2),
                'humidity': round(max(45, min(85, hum)), 2),
                'soil_moisture': round(random.uniform(60, 80), 2),
                'nutrient_level': round(max(1.0, min(2.5, nutrientes)), 2),
                'ph_level': round(max(5.5, min(7.5, ph)), 2),
                'light_intensity': round(luz, 2),
                'co2_level': round(random.uniform(400, 500), 2),
                'timestamp': datetime.now()
            }
            
            cursor.execute("""
                INSERT INTO sensor_data 
                (sensor_id, temperature, humidity, soil_moisture, nutrient_level, ph_level, light_intensity, co2_level, timestamp)
                VALUES (%s, %s, %s, %s, %s, %s, %s, %s, %s)
            """, (
                datos['sensor_id'],
                datos['temperature'],
                datos['humidity'],
                datos['soil_moisture'],
                datos['nutrient_level'],
                datos['ph_level'],
                datos['light_intensity'],
                datos['co2_level'],
                datos['timestamp']
            ))
        
        conn.commit()
        print(f"üìä Datos de sensores insertados - {datetime.now().strftime('%H:%M:%S')}")
        
    except Exception as e:
        print(f"‚ùå Error insertando datos de sensores: {e}")
        conn.rollback()
    finally:
        cursor.close()
        conn.close()

def generar_predicciones():
    """Generar predicciones cada 5 minutos usando modelos de ML reales"""
    global ultima_prediccion, ml_models
    
    conn = get_db_connection()
    if not conn:
        return
    
    # Inicializar modelos ML si no est√°n inicializados
    if ml_models is None:
        ml_models = InvernaderoMLModels(conn)
    
    cursor = conn.cursor()
    
    try:
        # Obtener plantas activas
        cursor.execute("SELECT plant_id, plant_type FROM plants WHERE status = 'active'")
        plantas = cursor.fetchall()
        
        if not plantas:
            return
        
        # Obtener √∫ltima lectura de sensores para cada planta
        for plant_id, plant_type in plantas:
            # Buscar sensor relacionado con esta planta
            cursor.execute("""
                SELECT DISTINCT ON (sensor_id)
                    sensor_id, temperature, humidity, soil_moisture,
                    nutrient_level, ph_level, light_intensity, co2_level
                FROM sensor_data
                WHERE sensor_id LIKE %s
                ORDER BY sensor_id, timestamp DESC
                LIMIT 1
            """, (f'%{plant_type}%',))
            
            sensor_row = cursor.fetchone()
            
            if not sensor_row:
                # Si no hay datos, usar valores por defecto
                sensor_data = {
                    'temperature': 22.0,
                    'humidity': 65.0,
                    'soil_moisture': 70.0,
                    'nutrient_level': 1.7,
                    'ph_level': 6.6,
                    'light_intensity': 1000.0,
                    'co2_level': 450.0
                }
            else:
                sensor_data = {
                    'temperature': float(sensor_row[1]) if sensor_row[1] else 22.0,
                    'humidity': float(sensor_row[2]) if sensor_row[2] else 65.0,
                    'soil_moisture': float(sensor_row[3]) if sensor_row[3] else 70.0,
                    'nutrient_level': float(sensor_row[4]) if sensor_row[4] else 1.7,
                    'ph_level': float(sensor_row[5]) if sensor_row[5] else 6.6,
                    'light_intensity': float(sensor_row[6]) if sensor_row[6] else 1000.0,
                    'co2_level': float(sensor_row[7]) if sensor_row[7] else 450.0
                }
            
            # Predecir usando modelo ML
            rendimiento, confianza = ml_models.predecir_con_datos_sensor(sensor_data, plant_type)
            
            # Si el modelo no existe o falla, intentar entrenarlo primero
            if rendimiento is None:
                print(f"‚ö†Ô∏è Modelo no disponible para {plant_type}, entrenando...")
                success, _ = ml_models.entrenar_modelo_rendimiento(plant_type)
                if success:
                    rendimiento, confianza = ml_models.predecir_con_datos_sensor(sensor_data, plant_type)
                else:
                    # Usar valores por defecto si no se puede entrenar
                    if plant_type == 'rabano':
                        rendimiento = random.uniform(150, 220)
                    else:
                        rendimiento = random.uniform(100, 160)
                    confianza = random.uniform(0.7, 0.85)
            
            # Asegurar valores razonables
            if rendimiento is None or rendimiento <= 0:
                if plant_type == 'rabano':
                    rendimiento = random.uniform(150, 220)
                else:
                    rendimiento = random.uniform(100, 160)
            
            if confianza is None or confianza <= 0:
                confianza = random.uniform(0.7, 0.95)
            
            # Insertar predicci√≥n
            cursor.execute("""
                INSERT INTO predictions (plant_id, predicted_yield, prediction_date, confidence)
                VALUES (%s, %s, %s, %s)
            """, (plant_id, round(rendimiento, 2), datetime.now(), round(confianza, 3)))
            
            print(f"ü§ñ Predicci√≥n ML - {plant_type}: {round(rendimiento, 2)}g (confianza: {round(confianza, 3)})")
        
        conn.commit()
        ultima_prediccion = datetime.now()
        print(f"üéØ PREDICCIONES ML generadas - {ultima_prediccion.strftime('%H:%M:%S')}")
        
    except Exception as e:
        print(f"‚ùå Error generando predicciones: {e}")
        import traceback
        traceback.print_exc()
        conn.rollback()
    finally:
        cursor.close()
        conn.close()

def simulador_datos():
    """Hilo del simulador que genera datos continuamente"""
    global simulador_activo
    ciclo = 0
    ultima_prediccion_time = datetime.now()
    
    print("üöÄ Simulador de datos iniciado")
    print("üì° Generando datos de sensores cada 10 segundos...")
    print("üéØ Generando predicciones cada 5 minutos...")
    
    while simulador_activo:
        try:
            # Generar datos de sensores cada 10 segundos
            generar_datos_sensor()
            
            # ‚úÖ GENERAR PREDICCIONES CADA 5 MINUTOS
            tiempo_actual = datetime.now()
            if (tiempo_actual - ultima_prediccion_time).total_seconds() >= 300:  # 5 minutos
                generar_predicciones()
                ultima_prediccion_time = tiempo_actual
            
            ciclo += 1
            if ciclo % 6 == 0:  # Cada minuto aproximadamente
                print(f"üîÑ Ciclo {ciclo} completado")
            
            time.sleep(10)  # Esperar 10 segundos
            
        except Exception as e:
            print(f"üí• Error en simulador: {e}")
            time.sleep(10)

def iniciar_simulador():
    """Iniciar el simulador en un hilo separado"""
    global simulador_activo, simulador_thread, ml_models, pca_analyzer, etl_processor, olap_analyzer
    
    if simulador_activo:
        print("‚ö†Ô∏è Simulador ya est√° activo")
        return
    
    # Inicializar base de datos primero
    if not inicializar_base_datos():
        print("‚ùå No se pudo inicializar la base de datos")
        return
    
    # Inicializar Data Warehouse
    try:
        print("üì¶ Inicializando Data Warehouse...")
        conn = get_db_connection()
        if conn:
            # Ejecutar esquema DW
            cursor = conn.cursor()
            with open(os.path.join(os.path.dirname(__file__), '..', 'database', 'dw_schema.sql'), 'r') as f:
                cursor.execute(f.read())
            conn.commit()
            cursor.close()
            
            # Inicializar m√≥dulos BI
            ml_models = InvernaderoMLModels(conn)
            pca_analyzer = PCAAnalyzer(conn)
            etl_processor = ETLProcessor(conn)
            olap_analyzer = OLAPAnalyzer(conn)
            
            # Ejecutar ETL inicial
            print("üîÑ Ejecutando ETL inicial...")
            etl_processor.execute_etl()
            
            # Aplicar PCA inicial
            print("üìä Aplicando PCA inicial...")
            pca_analyzer.aplicar_pca()
            pca_analyzer.guardar_resultados_pca()
            
            # Entrenar modelos ML iniciales
            print("ü§ñ Entrenando modelos ML iniciales...")
            ml_models.entrenar_modelo_rendimiento('rabano')
            ml_models.entrenar_modelo_rendimiento('cilantro')
            
            conn.close()
            print("‚úÖ Data Warehouse y m√≥dulos BI inicializados")
    except Exception as e:
        print(f"‚ö†Ô∏è Error inicializando DW/BI (continuando...): {e}")
        import traceback
        traceback.print_exc()
    
    simulador_activo = True
    simulador_thread = threading.Thread(target=simulador_datos)
    simulador_thread.daemon = True
    simulador_thread.start()
    print("‚úÖ Simulador iniciado correctamente")

def detener_simulador():
    """Detener el simulador"""
    global simulador_activo
    simulador_activo = False
    print("üõë Simulador detenido")

# ===== RUTAS PRINCIPALES =====
@app.route('/')
def index():
    return render_template('index.html')

@app.route('/monitor')
def monitor():
    return render_template('monitor.html')

@app.route('/predicciones')
def predicciones():
    return render_template('predicciones.html')

@app.route('/analytics')
def analytics():
    return render_template('dashboard_avanzado.html')

@app.route('/reportes')
def reportes():
    today = datetime.now().strftime('%Y-%m-%d')
    return render_template('reportes.html', today=today)

# ===== RUTAS DE CONTROL DEL SIMULADOR =====
@app.route('/api/simulador/iniciar')
def api_simulador_iniciar():
    """API para iniciar el simulador"""
    try:
        iniciar_simulador()
        return jsonify({
            'status': 'success',
            'message': 'Simulador iniciado correctamente',
            'activo': simulador_activo
        })
    except Exception as e:
        return jsonify({
            'status': 'error',
            'message': f'Error iniciando simulador: {str(e)}'
        })

@app.route('/api/simulador/detener')
def api_simulador_detener():
    """API para detener el simulador"""
    try:
        detener_simulador()
        return jsonify({
            'status': 'success',
            'message': 'Simulador detenido correctamente',
            'activo': simulador_activo
        })
    except Exception as e:
        return jsonify({
            'status': 'error',
            'message': f'Error deteniendo simulador: {str(e)}'
        })

@app.route('/api/simulador/estado')
def api_simulador_estado():
    """API para obtener el estado del simulador"""
    return jsonify({
        'activo': simulador_activo,
        'mensaje': 'Simulador activo' if simulador_activo else 'Simulador inactivo',
        'ultima_prediccion': ultima_prediccion.isoformat() if ultima_prediccion else None
    })

# ===== APIs PARA DATOS CON FILTROS DE FECHA Y HORA =====
@app.route('/api/sensors')
def api_sensors():
    """API para datos de sensores con filtros de fecha y hora"""
    start_date = request.args.get('start_date')
    end_date = request.args.get('end_date')
    start_time = request.args.get('start_time')
    end_time = request.args.get('end_time')
    
    conn = get_db_connection()
    if not conn:
        return jsonify({'error': 'No database connection'})
    
    cursor = conn.cursor()
    try:
        # Construir query con filtros de fecha y hora
        query = """
            SELECT sensor_id, temperature, humidity, light_intensity, nutrient_level, ph_level, timestamp 
            FROM sensor_data 
        """
        
        where_conditions = []
        params = []
        
        if start_date and start_time:
            start_datetime = f"{start_date} {start_time}"
            where_conditions.append("timestamp >= %s")
            params.append(start_datetime)
        elif start_date:
            where_conditions.append("timestamp >= %s")
            params.append(start_date)
            
        if end_date and end_time:
            end_datetime = f"{end_date} {end_time}"
            where_conditions.append("timestamp <= %s")
            params.append(end_datetime)
        elif end_date:
            where_conditions.append("timestamp <= %s")
            params.append(end_date + " 23:59:59")
        
        if where_conditions:
            query += " WHERE " + " AND ".join(where_conditions)
        
        query += " ORDER BY timestamp DESC LIMIT 100"
        
        cursor.execute(query, params)
        
        sensors = []
        for row in cursor.fetchall():
            sensors.append({
                'sensor_id': row[0],
                'temperature': float(row[1]) if row[1] is not None else 0,
                'humidity': float(row[2]) if row[2] is not None else 0,
                'light': float(row[3]) if row[3] is not None else 0,
                'nutrients': float(row[4]) if row[4] is not None else 0,
                'ph': float(row[5]) if row[5] is not None else 0,
                'timestamp': row[6].isoformat() if row[6] else ''
            })
        
        return jsonify({
            'sensors': sensors,
            'filtros_aplicados': {
                'start_date': start_date,
                'end_date': end_date,
                'start_time': start_time,
                'end_time': end_time
            }
        })
    except Exception as e:
        return jsonify({'error': str(e)})
    finally:
        cursor.close()
        conn.close()

@app.route('/api/predictions')
def api_predictions():
    """API para predicciones con filtros de fecha y hora"""
    start_date = request.args.get('start_date')
    end_date = request.args.get('end_date')
    start_time = request.args.get('start_time')
    end_time = request.args.get('end_time')
    
    conn = get_db_connection()
    if not conn:
        return jsonify({'error': 'No database connection'})
    
    cursor = conn.cursor()
    try:
        # Construir query con filtros de fecha y hora
        query = """
            SELECT p.prediction_id, pl.plant_type, p.predicted_yield, p.prediction_date, p.confidence
            FROM predictions p
            JOIN plants pl ON p.plant_id = pl.plant_id
        """
        
        where_conditions = []
        params = []
        
        if start_date and start_time:
            start_datetime = f"{start_date} {start_time}"
            where_conditions.append("p.prediction_date >= %s")
            params.append(start_datetime)
        elif start_date:
            where_conditions.append("p.prediction_date >= %s")
            params.append(start_date)
            
        if end_date and end_time:
            end_datetime = f"{end_date} {end_time}"
            where_conditions.append("p.prediction_date <= %s")
            params.append(end_datetime)
        elif end_date:
            where_conditions.append("p.prediction_date <= %s")
            params.append(end_date + " 23:59:59")
        
        if where_conditions:
            query += " WHERE " + " AND ".join(where_conditions)
        
        query += " ORDER BY p.prediction_date DESC LIMIT 100"
        
        cursor.execute(query, params)
        
        predictions = []
        for row in cursor.fetchall():
            predictions.append({
                'id': row[0],
                'plant_type': row[1],
                'yield': float(row[2]) if row[2] is not None else 0,
                'date': row[3].isoformat() if row[3] else '',
                'confidence': float(row[4]) if row[4] is not None else 0
            })
        
        return jsonify({
            'predictions': predictions,
            'filtros_aplicados': {
                'start_date': start_date,
                'end_date': end_date,
                'start_time': start_time,
                'end_time': end_time
            }
        })
    except Exception as e:
        return jsonify({'error': str(e)})
    finally:
        cursor.close()
        conn.close()

@app.route('/api/datos_monitor')
def api_datos_monitor():
    """API espec√≠fica para el monitor con datos completos y filtros de fecha"""
    start_date = request.args.get('start_date')
    end_date = request.args.get('end_date')
    start_time = request.args.get('start_time')
    end_time = request.args.get('end_time')
    
    conn = get_db_connection()
    if not conn:
        return jsonify({'error': 'No database connection'})
    
    cursor = conn.cursor()
    try:
        # Construir query con filtros de fecha y hora
        query = """
            SELECT DISTINCT ON (sensor_id) 
                   sensor_id, temperature, humidity, nutrient_level, ph_level, 
                   light_intensity, co2_level, timestamp
            FROM sensor_data 
        """
        
        where_conditions = []
        params = []
        
        if start_date and start_time:
            start_datetime = f"{start_date} {start_time}"
            where_conditions.append("timestamp >= %s")
            params.append(start_datetime)
        elif start_date:
            where_conditions.append("timestamp >= %s")
            params.append(start_date)
            
        if end_date and end_time:
            end_datetime = f"{end_date} {end_time}"
            where_conditions.append("timestamp <= %s")
            params.append(end_datetime)
        elif end_date:
            where_conditions.append("timestamp <= %s")
            params.append(end_date + " 23:59:59")
        
        if where_conditions:
            query += " WHERE " + " AND ".join(where_conditions)
        
        query += " ORDER BY sensor_id, timestamp DESC"
        
        cursor.execute(query, params)
        
        sensores = []
        for row in cursor.fetchall():
            if 'rabano' in row[0].lower():
                tipo_planta = 'rabano'
            elif 'cilantro' in row[0].lower():
                tipo_planta = 'cilantro'
            else:
                tipo_planta = 'general'
                
            sensores.append({
                'sensor_id': row[0],
                'temperatura': float(row[1]) if row[1] is not None else 22.0,
                'humedad': float(row[2]) if row[2] is not None else 65.0,
                'nutrientes': float(row[3]) if row[3] is not None else 1.5,
                'ph': float(row[4]) if row[4] is not None else 6.5,
                'luminosidad': float(row[5]) if row[5] is not None else 800,
                'co2': float(row[6]) if row[6] is not None else 450,
                'conductividad': float(row[3]) * 2 if row[3] is not None else 3.0,
                'tipo_planta': tipo_planta,
                'timestamp': row[7].isoformat() if row[7] else datetime.now().isoformat()
            })
        
        return jsonify({
            'sensores': sensores,
            'total_sensores': len(sensores),
            'timestamp_actualizacion': datetime.now().isoformat(),
            'filtros_aplicados': {
                'start_date': start_date,
                'end_date': end_date,
                'start_time': start_time,
                'end_time': end_time
            }
        })
        
    except Exception as e:
        print(f"Error en api_datos_monitor: {e}")
        return jsonify({'error': str(e)})
    finally:
        cursor.close()
        conn.close()

@app.route('/api/predicciones_completas')
def api_predicciones_completas():
    """API para predicciones de ambas plantas con filtros de fecha y hora"""
    start_date = request.args.get('start_date')
    end_date = request.args.get('end_date')
    start_time = request.args.get('start_time')
    end_time = request.args.get('end_time')
    
    conn = get_db_connection()
    if not conn:
        return jsonify({'error': 'No database connection'})
    
    cursor = conn.cursor()
    try:
        # Construir query con filtros de fecha y hora
        query = """
            SELECT pl.plant_type, 
                   AVG(p.predicted_yield) as rendimiento_promedio,
                   AVG(p.confidence) as confianza_promedio,
                   COUNT(*) as total_predicciones
            FROM predictions p
            JOIN plants pl ON p.plant_id = pl.plant_id
        """
        
        where_conditions = []
        params = []
        
        if start_date and start_time:
            start_datetime = f"{start_date} {start_time}"
            where_conditions.append("p.prediction_date >= %s")
            params.append(start_datetime)
        elif start_date:
            where_conditions.append("p.prediction_date >= %s")
            params.append(start_date)
            
        if end_date and end_time:
            end_datetime = f"{end_date} {end_time}"
            where_conditions.append("p.prediction_date <= %s")
            params.append(end_datetime)
        elif end_date:
            where_conditions.append("p.prediction_date <= %s")
            params.append(end_date + " 23:59:59")
        
        # Si no hay filtros, usar √∫ltimo d√≠a por defecto
        if not where_conditions:
            where_conditions.append("p.prediction_date >= NOW() - INTERVAL '1 day'")
        
        if where_conditions:
            query += " WHERE " + " AND ".join(where_conditions)
        
        query += " GROUP BY pl.plant_type"
        
        cursor.execute(query, params)
        
        predicciones = {}
        for row in cursor.fetchall():
            plant_type = row[0]
            dias_cosecha = 15 if plant_type == 'rabano' else 25
            
            factores_riesgo = []
            confianza = float(row[2]) if row[2] else 0.85

            if confianza < 0.7:
                factores_riesgo = ['Humedad variable', 'Temperatura inestable']
            elif confianza < 0.8:
                factores_riesgo = ['Ligera variaci√≥n en nutrientes']
            
            predicciones[plant_type] = {
                'rendimiento_previsto': float(row[1]) if row[1] else (180 if plant_type == 'rabano' else 130),
                'probabilidad_exito': confianza,
                'dias_cosecha': dias_cosecha,
                'factores_riesgo': factores_riesgo,
                'total_predicciones': row[3]
            }
        
        # Asegurar que tenemos datos para ambas plantas
        if 'rabano' not in predicciones:
            predicciones['rabano'] = {
                'rendimiento_previsto': 185.5,
                'probabilidad_exito': 0.87,
                'dias_cosecha': 15,
                'factores_riesgo': [],
                'total_predicciones': 0
            }
        
        if 'cilantro' not in predicciones:
            predicciones['cilantro'] = {
                'rendimiento_previsto': 135.2,
                'probabilidad_exito': 0.82,
                'dias_cosecha': 25,
                'factores_riesgo': ['Humedad ligeramente alta'],
                'total_predicciones': 0
            }
        
        return jsonify({
            'predicciones': predicciones,
            'filtros_aplicados': {
                'start_date': start_date,
                'end_date': end_date,
                'start_time': start_time,
                'end_time': end_time
            }
        })
        
    except Exception as e:
        print(f"Error en api_predicciones_completas: {e}")
        return jsonify({'error': str(e)})
    finally:
        cursor.close()
        conn.close()

@app.route('/api/graficos_tiempo_real')
def api_graficos_tiempo_real():
    """API para datos de gr√°ficos en tiempo real con filtros de fecha y hora"""
    start_date = request.args.get('start_date')
    end_date = request.args.get('end_date')
    start_time = request.args.get('start_time')
    end_time = request.args.get('end_time')
    
    conn = get_db_connection()
    if not conn:
        return jsonify({'error': 'No database connection'})
    
    cursor = conn.cursor()
    try:
        # Construir query con filtros de fecha y hora
        query = """
            SELECT timestamp, temperature, humidity, nutrient_level, ph_level
            FROM sensor_data 
        """
        
        where_conditions = []
        params = []
        
        if start_date and start_time:
            start_datetime = f"{start_date} {start_time}"
            where_conditions.append("timestamp >= %s")
            params.append(start_datetime)
        elif start_date:
            where_conditions.append("timestamp >= %s")
            params.append(start_date)
            
        if end_date and end_time:
            end_datetime = f"{end_date} {end_time}"
            where_conditions.append("timestamp <= %s")
            params.append(end_datetime)
        elif end_date:
            where_conditions.append("timestamp <= %s")
            params.append(end_date + " 23:59:59")
        
        # Si no hay filtros, usar √∫ltimas 12 horas por defecto
        if not where_conditions:
            where_conditions.append("timestamp >= NOW() - INTERVAL '12 hours'")
        
        if where_conditions:
            query += " WHERE " + " AND ".join(where_conditions)
        
        query += " ORDER BY timestamp ASC"
        
        cursor.execute(query, params)
        
        datos_temperatura = []
        datos_humedad = []
        datos_nutrientes = []
        datos_ph = []
        
        for row in cursor.fetchall():
            timestamp, temp, hum, nut, ph = row
            datos_temperatura.append({
                'x': timestamp.isoformat(),
                'y': float(temp) if temp is not None else 22.0
            })
            datos_humedad.append({
                'x': timestamp.isoformat(), 
                'y': float(hum) if hum is not None else 65.0
            })
            datos_nutrientes.append({
                'x': timestamp.isoformat(),
                'y': float(nut) if nut is not None else 1.7
            })
            datos_ph.append({
                'x': timestamp.isoformat(),
                'y': float(ph) if ph is not None else 6.6
            })
        
        return jsonify({
            'temperatura': datos_temperatura,
            'humedad': datos_humedad,
            'nutrientes': datos_nutrientes,
            'ph': datos_ph,
            'ultima_actualizacion': datetime.now().isoformat(),
            'filtros_aplicados': {
                'start_date': start_date,
                'end_date': end_date,
                'start_time': start_time,
                'end_time': end_time
            }
        })
        
    except Exception as e:
        print(f"Error en api_graficos_tiempo_real: {e}")
        return jsonify({'error': str(e)})
    finally:
        cursor.close()
        conn.close()

@app.route('/api/estado_actual')
def api_estado_actual():
    """API para datos en tiempo real del dashboard"""
    conn = get_db_connection()
    if not conn:
        return jsonify({'error': 'No database connection'})
    
    cursor = conn.cursor()
    try:
        cursor.execute("""
            SELECT DISTINCT ON (sensor_id) 
                   sensor_id, temperature, humidity, nutrient_level, ph_level, 
                   light_intensity, co2_level, timestamp
            FROM sensor_data 
            ORDER BY sensor_id, timestamp DESC
        """)
        
        sensores = []
        for row in cursor.fetchall():
            tipo_planta = 'rabano' if 'rabano' in row[0].lower() else 'cilantro'
            sensores.append({
                'sensor_id': row[0],
                'temperatura': float(row[1]) if row[1] is not None else 0,
                'humedad': float(row[2]) if row[2] is not None else 0,
                'nutrientes': float(row[3]) if row[3] is not None else 0,
                'ph': float(row[4]) if row[4] is not None else 0,
                'luminosidad': float(row[5]) if row[5] is not None else 0,
                'co2': float(row[6]) if row[6] is not None else 0,
                'conductividad': float(row[3]) * 2 if row[3] is not None else 0,
                'tipo_planta': tipo_planta,
                'timestamp': row[7].isoformat() if row[7] else ''
            })
        
        cursor.execute("""
            SELECT plant_type, AVG(predicted_yield), AVG(confidence)
            FROM predictions p
            JOIN plants pl ON p.plant_id = pl.plant_id
            WHERE p.prediction_date >= NOW() - INTERVAL '1 day'
            GROUP BY plant_type
        """)
        
        predicciones = {}
        for row in cursor.fetchall():
            dias_cosecha = 15 if row[0] == 'rabano' else 25
            factores_riesgo = []
            
            if row[2] and float(row[2]) < 0.8:
                factores_riesgo = ['Humedad variable', 'Temperatura inestable']
            
            predicciones[row[0]] = {
                'rendimiento_previsto': float(row[1]) if row[1] else 0,
                'probabilidad_exito': float(row[2]) if row[2] else 0,
                'dias_cosecha': dias_cosecha,
                'factores_riesgo': factores_riesgo
            }
        
        if 'rabano' not in predicciones:
            predicciones['rabano'] = {
                'rendimiento_previsto': 185.5,
                'probabilidad_exito': 0.87,
                'dias_cosecha': 15,
                'factores_riesgo': []
            }
        
        if 'cilantro' not in predicciones:
            predicciones['cilantro'] = {
                'rendimiento_previsto': 135.2,
                'probabilidad_exito': 0.82,
                'dias_cosecha': 25,
                'factores_riesgo': ['Humedad ligeramente alta']
            }
        
        estadisticas = {
            'total_sensores': len(sensores),
            'temp_promedio': round(sum(s['temperatura'] for s in sensores) / len(sensores), 1) if sensores else 0,
            'hum_promedio': round(sum(s['humedad'] for s in sensores) / len(sensores), 1) if sensores else 0
        }
        
        return jsonify({
            'sensores': sensores,
            'predicciones': predicciones,
            'estadisticas': estadisticas
        })
        
    except Exception as e:
        print(f"Error en api_estado_actual: {e}")
        return jsonify({'error': str(e)})
    finally:
        cursor.close()
        conn.close()

@app.route('/api/metricas_rendimiento')
def api_metricas_rendimiento():
    """API para m√©tricas de rendimiento con filtros de fecha y hora"""
    start_date = request.args.get('start_date')
    end_date = request.args.get('end_date')
    start_time = request.args.get('start_time')
    end_time = request.args.get('end_time')
    
    conn = get_db_connection()
    if not conn:
        return jsonify({'error': 'No database connection'})
    
    cursor = conn.cursor()
    try:
        # Construir query con filtros de fecha y hora
        query = """
            SELECT pl.plant_type, 
                   AVG(p.predicted_yield) as rendimiento_promedio,
                   COUNT(*) as total_predicciones
            FROM predictions p
            JOIN plants pl ON p.plant_id = pl.plant_id
        """
        
        where_conditions = []
        params = []
        
        if start_date and start_time:
            start_datetime = f"{start_date} {start_time}"
            where_conditions.append("p.prediction_date >= %s")
            params.append(start_datetime)
        elif start_date:
            where_conditions.append("p.prediction_date >= %s")
            params.append(start_date)
            
        if end_date and end_time:
            end_datetime = f"{end_date} {end_time}"
            where_conditions.append("p.prediction_date <= %s")
            params.append(end_datetime)
        elif end_date:
            where_conditions.append("p.prediction_date <= %s")
            params.append(end_date + " 23:59:59")
        
        # Si no hay filtros, usar √∫ltima semana por defecto
        if not where_conditions:
            where_conditions.append("p.prediction_date >= NOW() - INTERVAL '7 days'")
        
        if where_conditions:
            query += " WHERE " + " AND ".join(where_conditions)
        
        query += " GROUP BY pl.plant_type"
        
        cursor.execute(query, params)
        
        metricas = []
        for row in cursor.fetchall():
            metricas.append({
                'tipo_planta': row[0],
                'rendimiento_promedio': float(row[1]) if row[1] else 0,
                'total_predicciones': row[2]
            })
        
        plantas_encontradas = [m['tipo_planta'] for m in metricas]
        if 'rabano' not in plantas_encontradas:
            metricas.append({
                'tipo_planta': 'rabano',
                'rendimiento_promedio': 185.5,
                'total_predicciones': 0
            })
        if 'cilantro' not in plantas_encontradas:
            metricas.append({
                'tipo_planta': 'cilantro',
                'rendimiento_promedio': 135.2,
                'total_predicciones': 0
            })
        
        return jsonify({
            'metricas': metricas,
            'filtros_aplicados': {
                'start_date': start_date,
                'end_date': end_date,
                'start_time': start_time,
                'end_time': end_time
            }
        })
    except Exception as e:
        return jsonify({'error': str(e)})
    finally:
        cursor.close()
        conn.close()

# ===== NUEVAS APIS PARA REPORTES =====
@app.route('/api/reportes/sensores')
def api_reportes_sensores():
    """API para generar reportes de sensores con filtros precisos"""
    start_date = request.args.get('start_date')
    end_date = request.args.get('end_date')
    start_time = request.args.get('start_time')
    end_time = request.args.get('end_time')
    formato = request.args.get('formato', 'json')  # json o csv
    
    conn = get_db_connection()
    if not conn:
        return jsonify({'error': 'No database connection'})
    
    cursor = conn.cursor()
    try:
        # Construir query con filtros de fecha y hora
        query = """
            SELECT sensor_id, temperature, humidity, soil_moisture, nutrient_level, 
                   ph_level, light_intensity, co2_level, timestamp
            FROM sensor_data 
        """
        
        where_conditions = []
        params = []
        
        if start_date and start_time:
            start_datetime = f"{start_date} {start_time}"
            where_conditions.append("timestamp >= %s")
            params.append(start_datetime)
        elif start_date:
            where_conditions.append("timestamp >= %s")
            params.append(start_date)
            
        if end_date and end_time:
            end_datetime = f"{end_date} {end_time}"
            where_conditions.append("timestamp <= %s")
            params.append(end_datetime)
        elif end_date:
            where_conditions.append("timestamp <= %s")
            params.append(end_date + " 23:59:59")
        
        if where_conditions:
            query += " WHERE " + " AND ".join(where_conditions)
        
        query += " ORDER BY timestamp DESC"
        
        cursor.execute(query, params)
        
        datos = []
        for row in cursor.fetchall():
            datos.append({
                'sensor_id': row[0],
                'temperature': float(row[1]) if row[1] is not None else 0,
                'humidity': float(row[2]) if row[2] is not None else 0,
                'soil_moisture': float(row[3]) if row[3] is not None else 0,
                'nutrient_level': float(row[4]) if row[4] is not None else 0,
                'ph_level': float(row[5]) if row[5] is not None else 0,
                'light_intensity': float(row[6]) if row[6] is not None else 0,
                'co2_level': float(row[7]) if row[7] is not None else 0,
                'timestamp': row[8].isoformat() if row[8] else ''
            })
        
        if formato == 'csv':
            # Generar CSV
            output = io.StringIO()
            writer = csv.writer(output)
            writer.writerow(['Sensor ID', 'Temperature', 'Humidity', 'Soil Moisture', 
                           'Nutrient Level', 'pH Level', 'Light Intensity', 'CO2 Level', 'Timestamp'])
            
            for dato in datos:
                writer.writerow([
                    dato['sensor_id'],
                    dato['temperature'],
                    dato['humidity'],
                    dato['soil_moisture'],
                    dato['nutrient_level'],
                    dato['ph_level'],
                    dato['light_intensity'],
                    dato['co2_level'],
                    dato['timestamp']
                ])
            
            output.seek(0)
            return send_file(
                io.BytesIO(output.getvalue().encode('utf-8')),
                mimetype='text/csv',
                as_attachment=True,
                download_name=f'reporte_sensores_{datetime.now().strftime("%Y%m%d_%H%M%S")}.csv'
            )
        else:
            return jsonify({
                'datos': datos,
                'total_registros': len(datos),
                'filtros_aplicados': {
                    'start_date': start_date,
                    'end_date': end_date,
                    'start_time': start_time,
                    'end_time': end_time
                }
            })
            
    except Exception as e:
        return jsonify({'error': str(e)})
    finally:
        cursor.close()
        conn.close()

# ===== APIs PARA FUNCIONALIDADES BI =====
@app.route('/api/bi/pca/analisis')
def api_pca_analisis():
    """API para obtener an√°lisis PCA"""
    global pca_analyzer
    conn = get_db_connection()
    if not conn:
        return jsonify({'error': 'No database connection'})
    
    if pca_analyzer is None:
        pca_analyzer = PCAAnalyzer(conn)
    
    resultado = pca_analyzer.aplicar_pca()
    if resultado:
        contribuciones = pca_analyzer.obtener_contribuciones_features()
        return jsonify({
            'success': True,
            'pca_info': resultado['info'],
            'contribuciones': contribuciones
        })
    return jsonify({'error': 'Error aplicando PCA'})

@app.route('/api/bi/ml/entrenar')
def api_ml_entrenar():
    """API para entrenar modelos ML"""
    global ml_models
    plant_type = request.args.get('plant_type', 'general')
    
    conn = get_db_connection()
    if not conn:
        return jsonify({'error': 'No database connection'})
    
    if ml_models is None:
        ml_models = InvernaderoMLModels(conn)
    
    success, metrics = ml_models.entrenar_modelo_rendimiento(plant_type)
    if success:
        return jsonify({
            'success': True,
            'plant_type': plant_type,
            'metrics': metrics
        })
    return jsonify({'error': 'Error entrenando modelo'})

@app.route('/api/bi/etl/ejecutar')
def api_etl_ejecutar():
    """API para ejecutar proceso ETL"""
    global etl_processor
    conn = get_db_connection()
    if not conn:
        return jsonify({'error': 'No database connection'})
    
    if etl_processor is None:
        etl_processor = ETLProcessor(conn)
    
    success = etl_processor.execute_etl()
    if success:
        return jsonify({'success': True, 'message': 'ETL ejecutado correctamente'})
    return jsonify({'error': 'Error ejecutando ETL'})

@app.route('/api/bi/olap/drilldown')
def api_olap_drilldown():
    """API para operaci√≥n OLAP Drill-Down"""
    global olap_analyzer
    nivel_inicial = request.args.get('nivel_inicial', 'mes')
    nivel_detalle = request.args.get('nivel_detalle', 'dia')
    tipo_planta = request.args.get('tipo_planta')
    
    conn = get_db_connection()
    if not conn:
        return jsonify({'error': 'No database connection'})
    
    if olap_analyzer is None:
        olap_analyzer = OLAPAnalyzer(conn)
    
    resultados = olap_analyzer.drill_down(nivel_inicial, nivel_detalle, tipo_planta)
    return jsonify({'success': True, 'data': resultados})

@app.route('/api/bi/olap/slice')
def api_olap_slice():
    """API para operaci√≥n OLAP Slice"""
    global olap_analyzer
    dimension = request.args.get('dimension', 'tipo_planta')
    valor = request.args.get('valor')
    
    conn = get_db_connection()
    if not conn:
        return jsonify({'error': 'No database connection'})
    
    if olap_analyzer is None:
        olap_analyzer = OLAPAnalyzer(conn)
    
    resultados = olap_analyzer.slice(dimension, valor)
    return jsonify({'success': True, 'data': resultados})

@app.route('/api/bi/olap/pivot')
def api_olap_pivot():
    """API para operaci√≥n OLAP Pivot"""
    global olap_analyzer
    dimension_filas = request.args.get('filas', 'fecha')
    dimension_columnas = request.args.get('columnas', 'tipo_planta')
    medida = request.args.get('medida', 'temperatura')
    
    conn = get_db_connection()
    if not conn:
        return jsonify({'error': 'No database connection'})
    
    if olap_analyzer is None:
        olap_analyzer = OLAPAnalyzer(conn)
    
    resultados = olap_analyzer.pivot(dimension_filas, dimension_columnas, medida)
    return jsonify({'success': True, 'data': resultados})

@app.route('/api/bi/clustering')
def api_clustering():
    """API para clustering de datos"""
    n_clusters = int(request.args.get('n_clusters', 3))
    
    conn = get_db_connection()
    if not conn:
        return jsonify({'error': 'No database connection'})
    
    clustering = ClusteringModels(conn)
    resultados = clustering.kmeans_clustering(n_clusters)
    
    if resultados:
        return jsonify({'success': True, 'data': resultados})
    return jsonify({'error': 'Error en clustering'})

@app.route('/api/reportes/predicciones')
def api_reportes_predicciones():
    """API para generar reportes de predicciones con filtros precisos"""
    start_date = request.args.get('start_date')
    end_date = request.args.get('end_date')
    start_time = request.args.get('start_time')
    end_time = request.args.get('end_time')
    formato = request.args.get('formato', 'json')  # json o csv
    
    conn = get_db_connection()
    if not conn:
        return jsonify({'error': 'No database connection'})
    
    cursor = conn.cursor()
    try:
        # Construir query con filtros de fecha y hora
        query = """
            SELECT p.prediction_id, pl.plant_type, p.predicted_yield, p.prediction_date, p.confidence
            FROM predictions p
            JOIN plants pl ON p.plant_id = pl.plant_id
        """
        
        where_conditions = []
        params = []
        
        if start_date and start_time:
            start_datetime = f"{start_date} {start_time}"
            where_conditions.append("p.prediction_date >= %s")
            params.append(start_datetime)
        elif start_date:
            where_conditions.append("p.prediction_date >= %s")
            params.append(start_date)
            
        if end_date and end_time:
            end_datetime = f"{end_date} {end_time}"
            where_conditions.append("p.prediction_date <= %s")
            params.append(end_datetime)
        elif end_date:
            where_conditions.append("p.prediction_date <= %s")
            params.append(end_date + " 23:59:59")
        
        if where_conditions:
            query += " WHERE " + " AND ".join(where_conditions)
        
        query += " ORDER BY p.prediction_date DESC"
        
        cursor.execute(query, params)
        
        datos = []
        for row in cursor.fetchall():
            datos.append({
                'prediction_id': row[0],
                'plant_type': row[1],
                'predicted_yield': float(row[2]) if row[2] is not None else 0,
                'prediction_date': row[3].isoformat() if row[3] else '',
                'confidence': float(row[4]) if row[4] is not None else 0
            })
        
        if formato == 'csv':
            # Generar CSV
            output = io.StringIO()
            writer = csv.writer(output)
            writer.writerow(['Prediction ID', 'Plant Type', 'Predicted Yield', 'Prediction Date', 'Confidence'])
            
            for dato in datos:
                writer.writerow([
                    dato['prediction_id'],
                    dato['plant_type'],
                    dato['predicted_yield'],
                    dato['prediction_date'],
                    dato['confidence']
                ])
            
            output.seek(0)
            return send_file(
                io.BytesIO(output.getvalue().encode('utf-8')),
                mimetype='text/csv',
                as_attachment=True,
                download_name=f'reporte_predicciones_{datetime.now().strftime("%Y%m%d_%H%M%S")}.csv'
            )
        else:
            return jsonify({
                'datos': datos,
                'total_registros': len(datos),
                'filtros_aplicados': {
                    'start_date': start_date,
                    'end_date': end_date,
                    'start_time': start_time,
                    'end_time': end_time
                }
            })
            
    except Exception as e:
        return jsonify({'error': str(e)})
    finally:
        cursor.close()
        conn.close()

if __name__ == '__main__':
    print("=== BIO-INVERNADERO INTELIGENTE ===")
    print("üåø Dashboard: http://localhost:5000")
    print("üìä Rutas disponibles:")
    print("   - / (Inicio)")
    print("   - /monitor (Monitoreo en tiempo real)")
    print("   - /predicciones (Predicciones IA)")
    print("   - /analytics (Dashboard avanzado)")
    print("   - /reportes (Reportes y exportaci√≥n)")
    print("üîå APIs de control:")
    print("   - /api/simulador/iniciar (Iniciar simulador)")
    print("   - /api/simulador/detener (Detener simulador)")
    print("   - /api/simulador/estado (Estado del simulador)")
    print("üìÖ APIs con filtros de fecha y hora:")
    print("   - /api/sensors?start_date=YYYY-MM-DD&start_time=HH:MM&end_date=YYYY-MM-DD&end_time=HH:MM")
    print("   - /api/predictions?start_date=YYYY-MM-DD&start_time=HH:MM&end_date=YYYY-MM-DD&end_time=HH:MM")
    print("üìä APIs de reportes:")
    print("   - /api/reportes/sensores?start_date=YYYY-MM-DD&start_time=HH:MM&end_date=YYYY-MM-DD&end_time=HH:MM&formato=csv")
    print("   - /api/reportes/predicciones?start_date=YYYY-MM-DD&start_time=HH:MM&end_date=YYYY-MM-DD&end_time=HH:MM&formato=csv")
    print("üöÄ Iniciando simulador autom√°ticamente...")
    print("üéØ Predicciones se generar√°n cada 5 minutos")
    
    # Iniciar simulador autom√°ticamente
    iniciar_simulador()
    
    print("‚úÖ Sistema listo!")
    app.run(debug=True, port=5000, use_reloader=False)